{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Pytorch\n",
    "\n",
    "Pytorch furnishes the tools essential for constructing and training complex models with ease. \n",
    "\n",
    "**The following are the key components of Pytorch:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensors\n",
    "\n",
    "A **tensor** is a general term used to describe a **array of any dimension** of numbers. Tensors generalize the concepts of **scalars**, **vectors**, and **matrices** to any number of dimensions.\n",
    "\n",
    "**Examples:**<br><br>\n",
    "**Images**: A color image can be represented as a 3D tensor of dimensions (Height, Width, Channels). For a 128x128 color image, the tensor shape might be (128, 128, 3), where 3 represents the RGB color channels.<br><br>\n",
    "**Video**: A video can be represented as a 4D tensor with dimensions (Frames, Height, Width, Channels). For a video of 30 frames, each frame being 128x128 pixels with 3 color channels, the shape might be (30, 128, 128, 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 3-dimensional tensor\n",
    "images = torch.rand((4, 28, 28))\n",
    "\n",
    "# Get the second image\n",
    "second_image = images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(second_image, cmap='gray')\n",
    "plt.axis('off') # disable axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 0]])\n",
      "tensor([[2, 1],\n",
      "        [1, 1]])\n",
      "tensor([[3, 2],\n",
      "        [2, 1]])\n",
      "tensor([[5, 3],\n",
      "        [3, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Power of matrix\n",
    "a = torch.tensor([[1, 1], [1, 0]])\n",
    "\n",
    "print(a)\n",
    "# print(torch.matrix_power(a, 0.4)) wrong\n",
    "print(torch.matrix_power(a, 2))\n",
    "print(torch.matrix_power(a, 3))\n",
    "print(torch.matrix_power(a, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network\n",
    "\n",
    "Pytorch provides robust tools for the creation and manipulation of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden_layer): Linear(in_features=10, out_features=64, bias=True)\n",
       "  (output_layer): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 64)\n",
    "        self.output_layer = nn.Linear(64, 2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        first_pass = self.hidden_layer(x)\n",
    "        second_pass = self.activation(first_pass)\n",
    "        return self.output_layer(second_pass)\n",
    "\n",
    "model = MLP(input_size=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4308, -0.1105], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.rand(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss Functions\n",
    "\n",
    "Loss functions play a pivotal role in guiding model optimization. These functions quantify the discrepancy between the predicted output and the actual target values. By minimizing this quantified error, a model can be trained to produce more accurate results. \n",
    "\n",
    "**Commonly used loss functions** :\n",
    "- Cross-entropy loss function (classification tasks)\n",
    "- Mean-Squared error (regression tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "target_tensor = torch.tensor([1])\n",
    "target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0486)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tensor = torch.tensor([[2.0, 5.0]])\n",
    "loss_value = loss_function(predicted_tensor, target_tensor)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9130)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tensor = torch.tensor([[1.5, 1.1]])\n",
    "loss_value = loss_function(predicted_tensor, target_tensor)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000000.0\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "predicted_tensor = torch.tensor([320000.0])\n",
    "actual_tensor = torch.tensor([300000.0])\n",
    "loss_value = loss_function(predicted_tensor, actual_tensor)\n",
    "print(loss_value.item()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optimizers\n",
    "\n",
    "Optimizer's primary function is to adjust the parameters of the model in response to the computed gradients aiming to minimize the loss function. \n",
    "\n",
    "**Well known optimizers**:\n",
    "- Stochastic Gradient Descent\n",
    "- Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Datasets and Data loaders\n",
    "\n",
    "The handling and preparation of data for training and evaluation is facilitated through two primary constructs, the dataset class and the data loader utility. \n",
    "\n",
    "The dataset class serves as blueprint for defining how data is accessed and transformed. It can do the heavy lifing of accessing and parsing directories and files. \n",
    "\n",
    "The dataloader utility wraps around the dataset object to provide batched, shuffled and parallized loading of data. It offers a streamlined interface for iterating over data batches during model training and evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Dataset class: This is like a recipe that tells your computer how to get the data it needs to learn from, including where to find it and how to parse it, if necessary.\n",
    "\n",
    "PyTorch Data Loader: Think of this as a delivery truck that brings the data to your AI in small, manageable loads called batches; this makes it easier for the AI to process and learn from the data.\n",
    "\n",
    "Batches: Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((3, 4), 12)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NumberProductDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = self.numbers[index]\n",
    "        number2 = self.numbers[index] + 1\n",
    "        return (number1, number2), number1 * number2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers)\n",
    "\n",
    "dataset = NumberProductDataset(\n",
    "    data_range=(0, 11)\n",
    ")\n",
    "\n",
    "data_sample = dataset[3]\n",
    "print(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 1, 2]), tensor([1, 2, 3])] tensor([0, 2, 6])\n",
      "[tensor([3, 4]), tensor([4, 5])] tensor([12, 20])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = NumberProductDataset(data_range=(0, 5))\n",
    "\n",
    "# Create a DataLoader instance\n",
    "dataloader = DataLoader(dataset, batch_size=3)\n",
    "\n",
    "# Iterating over batches\n",
    "for (num_pairs, products) in dataloader:\n",
    "    print(num_pairs, products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSumDataset(data_range=(1, 100))\n",
    "\n",
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(0, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Losses = 74332.43520\n",
      "Epoch 1: Sum of Batch Losses = 611.91237\n",
      "Epoch 2: Sum of Batch Losses = 119.86382\n",
      "Epoch 3: Sum of Batch Losses = 7.68462\n",
      "Epoch 4: Sum of Batch Losses = 4.53653\n",
      "Epoch 5: Sum of Batch Losses = 3.35680\n",
      "Epoch 6: Sum of Batch Losses = 2.72369\n",
      "Epoch 7: Sum of Batch Losses = 2.40381\n",
      "Epoch 8: Sum of Batch Losses = 2.18668\n",
      "Epoch 9: Sum of Batch Losses = 1.99949\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0.0\n",
    "    for number_pairs, sums in dataloader:  # Iterate over the batches\n",
    "        predictions = model(number_pairs)  # Compute the model output\n",
    "        loss = loss_function(predictions, sums)  # Compute the loss\n",
    "        loss.backward()  # Perform backpropagation\n",
    "        optimizer.step()  # Update the parameters\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        total_loss += loss.item()  # Add the loss for all batches\n",
    "\n",
    "    print(\"Epoch {}: Sum of Batch Losses = {:.5f}\".format(epoch, total_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.1315], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the data\n",
    "model(torch.tensor([3.0, 7.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
